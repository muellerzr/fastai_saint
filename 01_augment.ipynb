{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Augmentations\n",
    "> CutMix and MixUp based on the SAINT paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from fastcore.xtras import nested_attr\n",
    "from fastai.torch_core import to_device, apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def embed_data_mask(\n",
    "    x_cat:torch.Tensor, # Input categorical features\n",
    "    x_cont:torch.Tensor, # Input continouous features\n",
    "    cat_mask:torch.Tensor, # Mask of categorical inputs\n",
    "    cont_mask:torch.Tensor, # Mask of continouous inputs\n",
    "    net, # The SAINT architecture\n",
    "    vision_dset=False # Is the dataset a vision dataset\n",
    ") -> (\n",
    "    torch.Tensor, # New categorical input\n",
    "    torch.Tensor, # New categorical encoding\n",
    "    torch.Tensor # New continuous encoding\n",
    "):\n",
    "    \"Embed and mask the data through the embeddings with MLP attention\"\n",
    "    # Can we rewrite this as a `Module`\n",
    "    device = x_cont.device\n",
    "    def apply_offset(model, attr, tensor_type):\n",
    "        return nested_attr(f'{attr}_offset.type_as', model)(tensor_type)\n",
    "    \n",
    "    x_cat += apply_offset(net, 'categories', x_cat)\n",
    "    x_cat_enc = net.embeds(x_cat)\n",
    "    # n1,n2,n3 = BS,n_cont,n_cat\n",
    "    n1,n2 = x_cont.shape\n",
    "    _, n3 = x_cat.shape\n",
    "    \n",
    "    x_cont_enc = torch.empty(n1, n2, net.dim)\n",
    "    # Do we need this for loop, can it be done quicker?\n",
    "    for i in range(net.num_continuous):\n",
    "        x_cont_enc[:,i,:] = net.simpleMLP[i](x_cont[:,i])\n",
    "    \n",
    "    x_cont_enc = x_cont_enc.to(device)\n",
    "    \n",
    "    cat_mask_tmp = cat_mask + apply_offset(net, 'cat_mask', cat_mask)\n",
    "    con_mask_tmp = cont_mask + apply_offset(net, 'cont_mask', cont_mask)\n",
    "    \n",
    "    cat_mask_tmp = net.mask_embeds_cat(cat_mask_tmp)\n",
    "    cont_mask_tmp = net.mask_embeds_cont(cont_mask_tmp)\n",
    "    \n",
    "    x_cat_enc[cat_mask == 0] = cat_mask_tmp[cat_mask == 0]\n",
    "    x_cont_enc[cont_mask == 0] = cont_mask_tmp[cont_mask == 0]\n",
    "    \n",
    "    return x_cat, x_cat_enc, x_cont_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CutMix and MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def SAINTMixUp(\n",
    "    x1: torch.Tensor, # One tensor in a batch\n",
    "    x2: torch.Tensor, # Another random tensor in a batch\n",
    "    lam: float = 1, # Lambda to apply on inputs\n",
    "    y: torch.Tensor = None, # Targets\n",
    "    use_cuda:bool = True # Whether to perform action on the GPU\n",
    ") -> (\n",
    "    torch.Tensor, # Mixed up `x1`\n",
    "    torch.Tensor # Mixed up `x2`\n",
    "):\n",
    "    \"Mixing up inputs, and returning a pair of targets\"\n",
    "    \n",
    "    bs = x1.size()[0]\n",
    "    device = 'cpu' if not use_cuda else 'cuda'\n",
    "    idx = to_device(torch.randperm(bs), device)\n",
    "    \n",
    "    # Applies `mix` to both x1 and x2 on lam and at idx\n",
    "    def _mix(x, lam, idx): return lam * x + (1-lam) * x[idx,:]\n",
    "    mix_x1, mix_2 = apply(partial(_mix, lam=lam, idx=idx), (x1, x2))\n",
    "    \n",
    "    if y is not None:\n",
    "        y_a, y_b = y, y[idx]\n",
    "        return mix_x1, mix_x2, y_a, y_b\n",
    "    \n",
    "    return mix_1, mix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def SAINTCutMix(\n",
    "    x_cat: torch.Tensor, # One batch of categorical data\n",
    "    x_cont: torch.Tensor, # One batch of continuous data\n",
    "    lam:float = 0.1 # Lambda to apply on inputs\n",
    ") -> (\n",
    "    torch.Tensor, # Newly noised categorical features\n",
    "    torch.Tensor, # Newly noised continuous features\n",
    "):\n",
    "    \"Applies `CutMix` on the `x's`, noisifying the data\"\n",
    "    bs, device = x_cat.size()[0], x_cat.device\n",
    "    \n",
    "    idx = torch.randperm(bs)\n",
    "    def _apply_lambda(i, shape, lam, device):\n",
    "        return torch.from_numpy(np.random.choice(i, shape, p=[lam,1-lam])).to(device)\n",
    "    \n",
    "    cat_corr = _apply_lambda(2, x_cat.shape, lam, device)\n",
    "    cont_corr = _apply_lambda(2, x_cont.shape, lam, device)\n",
    "    x1, x2 = x_cat[idx,:], x_cont[idx,:]\n",
    "    x_cat_corr, x_cont_corr = x_cat.clone().detach(), x_cat.clone().detach()\n",
    "    \n",
    "    x_cat_corr[cat_corr==0] = x1[cat_corr==0]\n",
    "    x_cont_cor[cont_corr==0] = x2[cont_corr==0]\n",
    "    return x_cat_corr, x_cont_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_augment.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted stream_notebook.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
